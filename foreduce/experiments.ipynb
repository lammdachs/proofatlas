{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "seq_len = 3\n",
    "embed_dim = 4\n",
    "n_heads = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.stack([torch.rand(seq_len, embed_dim) for _ in range(batch_size)])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_q = nn.Linear(embed_dim, n_heads*embed_dim)\n",
    "w_k = nn.Linear(embed_dim, n_heads*embed_dim)\n",
    "w_v = nn.Linear(embed_dim, n_heads*embed_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import pi\n",
    "\n",
    "angles = [10000**(2 * i / embed_dim) for i in range(embed_dim//2)]\n",
    "rotations = torch.exp(1j * torch.matmul(torch.arange(seq_len).float().reshape(-1, 1), torch.tensor(angles).reshape(1, -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rotations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotations = rotations.reshape(1, seq_len, 1, embed_dim // 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotary_positional_embedding(q, k, rotations):\n",
    "    q_shape, k_shape = q.shape, k.shape\n",
    "    q = torch.view_as_complex(q.view(*q.shape[:-1], -1, 2))\n",
    "    k = torch.view_as_complex(k.view(*k.shape[:-1], -1, 2))\n",
    "    q = torch.view_as_real(q * rotations)\n",
    "    k = torch.view_as_real(k * rotations)\n",
    "    return q.view(q_shape), k.view(k_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = w_q(x).view(2, seq_len, n_heads, embed_dim)\n",
    "k = w_k(x).view(batch_size, seq_len, n_heads, embed_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "q, k = rotary_positional_embedding(q, k, rotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 2, 4]), torch.Size([2, 3, 2, 4]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.shape, k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_ = q.transpose(1, 2)\n",
    "k_ = k.transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 2, 3, 4]), torch.Size([2, 2, 3, 4]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_.shape, k_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "att = (q_ @ k_.transpose(-2, -1)) / (embed_dim ** 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "att2 = torch.einsum('bqhd,bkhd->bhqk', q, k) / (embed_dim ** 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 3, 3])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 3, 3])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask =  torch.tril(torch.ones(seq_len, seq_len)).reshape(1, 1, seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 3, 3])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.2417,    -inf,    -inf],\n",
       "          [-0.0382, -0.1512,    -inf],\n",
       "          [ 0.1328, -0.0423, -0.1108]],\n",
       "\n",
       "         [[ 0.2528,    -inf,    -inf],\n",
       "          [ 0.2026,  0.1229,    -inf],\n",
       "          [ 0.2069,  0.1221,  0.0035]]],\n",
       "\n",
       "\n",
       "        [[[-0.1954,    -inf,    -inf],\n",
       "          [ 0.0657, -0.0714,    -inf],\n",
       "          [ 0.1476,  0.1208, -0.0688]],\n",
       "\n",
       "         [[ 0.1839,    -inf,    -inf],\n",
       "          [ 0.2650,  0.1993,    -inf],\n",
       "          [ 0.1955,  0.2624, -0.0083]]]], grad_fn=<MaskedFillBackward0>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att.masked_fill(mask == 0, float('-inf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "att = nn.functional.softmax(att.masked_fill(mask == 0, float('-inf')), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1.0000, 0.0000, 0.0000],\n",
       "          [0.5282, 0.4718, 0.0000],\n",
       "          [0.3812, 0.3200, 0.2988]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000],\n",
       "          [0.5199, 0.4801, 0.0000],\n",
       "          [0.3657, 0.3360, 0.2984]]],\n",
       "\n",
       "\n",
       "        [[[1.0000, 0.0000, 0.0000],\n",
       "          [0.5342, 0.4658, 0.0000],\n",
       "          [0.3599, 0.3503, 0.2898]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000],\n",
       "          [0.5164, 0.4836, 0.0000],\n",
       "          [0.3467, 0.3706, 0.2827]]]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 2, 4])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = w_v(x).view(batch_size, seq_len, n_heads, embed_dim)\n",
    "v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = att @ v.transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = y2.transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.3518, -0.0209,  0.1209,  0.8380],\n",
       "          [-0.2491, -0.6931, -0.0226, -0.6212]],\n",
       "\n",
       "         [[-0.2574,  0.0482,  0.1386,  0.6419],\n",
       "          [-0.3487, -0.5973,  0.1157, -0.5271]],\n",
       "\n",
       "         [[-0.3084, -0.0112,  0.1889,  0.5804],\n",
       "          [-0.3979, -0.4648,  0.1492, -0.3965]]],\n",
       "\n",
       "\n",
       "        [[[-0.1169,  0.1278,  0.0732,  0.5716],\n",
       "          [-0.3541, -0.6073,  0.1750, -0.5830]],\n",
       "\n",
       "         [[-0.1740, -0.0159,  0.0567,  0.5575],\n",
       "          [-0.3966, -0.5161,  0.2535, -0.5247]],\n",
       "\n",
       "         [[-0.1855, -0.0683,  0.0909,  0.4691],\n",
       "          [-0.4448, -0.3442,  0.2976, -0.3843]]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.einsum('bhqk,bkhd->bqhd', att, v)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 2, 4])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_o = nn.Linear(n_heads*embed_dim, embed_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.8762, -0.2059,  0.5416,  0.0838],\n",
       "         [-0.7809, -0.3210,  0.5421,  0.0079],\n",
       "         [-0.7104, -0.3361,  0.5693, -0.0568]],\n",
       "\n",
       "        [[-0.7624, -0.3870,  0.4831, -0.0102],\n",
       "         [-0.7504, -0.4115,  0.4714, -0.0752],\n",
       "         [-0.6530, -0.4433,  0.4762, -0.1635]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_o(y.reshape(batch_size, seq_len, -1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fo-reduce",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
